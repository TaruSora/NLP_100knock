{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100knock_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaruSora/NLP_100knock/blob/main/100knock_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "90.機械翻訳のデータセットをダウンロードせよ．訓練データ，開発データ，評価データを整形し，必要に応じてトークン化などの前処理を行うこと．ただし，この段階ではトークンの単位として形態素（日本語）および単語（英語）を採用せよ."
      ],
      "metadata": {
        "id": "hl1IVM9eTojn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1deX4gTGRyzN",
        "outputId": "295eda71-24b6-4f42-86d8-584e0a7b9568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-17 03:56:48--  http://www.phontron.com/kftt/download/kftt-data-1.0.tar.gz\n",
            "Resolving www.phontron.com (www.phontron.com)... 208.113.196.149\n",
            "Connecting to www.phontron.com (www.phontron.com)|208.113.196.149|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99246893 (95M) [application/gzip]\n",
            "Saving to: ‘kftt-data-1.0.tar.gz’\n",
            "\n",
            "kftt-data-1.0.tar.g 100%[===================>]  94.65M  29.5MB/s    in 3.4s    \n",
            "\n",
            "2022-05-17 03:56:52 (28.0 MB/s) - ‘kftt-data-1.0.tar.gz’ saved [99246893/99246893]\n",
            "\n",
            "kftt-data-1.0/\n",
            "kftt-data-1.0/data/\n",
            "kftt-data-1.0/data/orig/\n",
            "kftt-data-1.0/data/orig/kyoto-tune.en\n",
            "kftt-data-1.0/data/orig/kyoto-dev.ja\n",
            "kftt-data-1.0/data/orig/kyoto-dev.en\n",
            "kftt-data-1.0/data/orig/kyoto-train.en\n",
            "kftt-data-1.0/data/orig/kyoto-tune.ja\n",
            "kftt-data-1.0/data/orig/kyoto-train.ja\n",
            "kftt-data-1.0/data/orig/kyoto-test.ja\n",
            "kftt-data-1.0/data/orig/kyoto-test.en\n",
            "kftt-data-1.0/data/tok/\n",
            "kftt-data-1.0/data/tok/kyoto-tune.en\n",
            "kftt-data-1.0/data/tok/kyoto-dev.ja\n",
            "kftt-data-1.0/data/tok/kyoto-train.cln.en\n",
            "kftt-data-1.0/data/tok/kyoto-dev.en\n",
            "kftt-data-1.0/data/tok/kyoto-train.en\n",
            "kftt-data-1.0/data/tok/kyoto-tune.ja\n",
            "kftt-data-1.0/data/tok/kyoto-train.cln.ja\n",
            "kftt-data-1.0/data/tok/kyoto-train.ja\n",
            "kftt-data-1.0/data/tok/kyoto-test.ja\n",
            "kftt-data-1.0/data/tok/kyoto-test.en\n",
            "kftt-data-1.0/README.txt\n"
          ]
        }
      ],
      "source": [
        "! wget http://www.phontron.com/kftt/download/kftt-data-1.0.tar.gz\n",
        "! tar xvzf kftt-data-1.0.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U --quiet ja_ginza\n",
        "! python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlOl7-NGZLfL",
        "outputId": "b7ab482e-a9d0-46a7-fd51-bfdf9e9d7c79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 59.1 MB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 59.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 457 kB 68.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 653 kB 63.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 59.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 78.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 8.0 MB/s \n",
            "\u001b[?25h  Building wheel for sudachidict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9 MB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.2.0) (3.2.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p /content/ginza-data\n",
        "! cat kftt-data-1.0/data/orig/kyoto-train.ja | sed 's/\\s+/ /g' | ginzame > /content/ginza-data/train.ginza.ja\n",
        "! cat kftt-data-1.0/data/orig/kyoto-dev.ja | sed 's/\\s+/ /g' | ginzame > /content/ginza-data/dev.ginza.ja\n",
        "! cat kftt-data-1.0/data/orig/kyoto-test.ja | sed 's/\\s+/ /g' | ginzame > /content/ginza-data/test.ginza.ja"
      ],
      "metadata": {
        "id": "d9Mv-_xhZTOo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data\n",
        "for src, dst in [\n",
        "    (\"/content/ginza-data/train.ginza.ja\", \"/content/data/train.ja\"),\n",
        "    (\"/content/ginza-data/dev.ginza.ja\", \"/content/data/dev.ja\"),\n",
        "    (\"/content/ginza-data/test.ginza.ja\", \"/content/data/test.ja\"),\n",
        "]:\n",
        "    with open(src) as f:\n",
        "        lst = []\n",
        "        tmp = []\n",
        "        for x in f:\n",
        "            x = x.strip()\n",
        "            if x == 'EOS':\n",
        "                lst.append(' '.join(tmp))\n",
        "                tmp = []\n",
        "            elif x != '':\n",
        "                tmp.append(x.split('\\t')[0])\n",
        "    with open(dst, 'w') as f:\n",
        "        for line in lst:\n",
        "            print(line, file=f)\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "for src, dst in [\n",
        "    (\"kftt-data-1.0/data/orig/kyoto-train.en\", \"/content/data/train.en\"),\n",
        "    (\"kftt-data-1.0/data/orig/kyoto-dev.en\", \"/content/data/dev.en\"),\n",
        "    (\"kftt-data-1.0/data/orig/kyoto-test.en\", \"/content/data/test.en\"),\n",
        "]:\n",
        "    with open(src) as f, open(dst, 'w') as g:\n",
        "        for x in f:\n",
        "            x = x.strip()\n",
        "            x = re.sub(r'\\s+', ' ', x)\n",
        "            x = nlp.make_doc(x)\n",
        "            x = ' '.join([doc.text for doc in x])\n",
        "            print(x, file=g)"
      ],
      "metadata": {
        "id": "1sWXsR9FUzAG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "91.90で準備したデータを用いて，ニューラル機械翻訳のモデルを学習せよ（ニューラルネットワークのモデルはTransformerやLSTMなど適当に選んでよい）．"
      ],
      "metadata": {
        "id": "k9WctYQ2buMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd /content/fairseq/\n",
        "!python -m pip install --editable .\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Ht1UjGx22o",
        "outputId": "8350ca58-abce-4119-d046-d4dc61ddb014"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 31357, done.\u001b[K\n",
            "remote: Total 31357 (delta 0), reused 0 (delta 0), pack-reused 31357\u001b[K\n",
            "Receiving objects: 100% (31357/31357), 21.57 MiB | 28.03 MiB/s, done.\n",
            "Resolving deltas: 100% (23130/23130), done.\n",
            "/content/fairseq\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+b5a039c) (1.21.6)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting bitarray\n",
            "  Downloading bitarray-2.5.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+b5a039c) (2019.12.20)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+b5a039c) (0.29.28)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+b5a039c) (0.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+b5a039c) (4.64.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+b5a039c) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+b5a039c) (1.11.0+cu113)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+b5a039c) (5.7.1)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 61.5 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+b5a039c) (3.10.0.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+b5a039c) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+b5a039c) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+b5a039c) (3.8.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=f4334bf3b68dda21db474780fcd72ac7334b83c87234b9083d8bfcb127305786\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.5.1 colorama-0.4.4 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.4.0 sacrebleu-2.0.0\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\""
      ],
      "metadata": {
        "id": "yDi5KSSg8zMK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess -s ja -t en \\\n",
        "    --trainpref /content/data/train \\\n",
        "    --validpref /content/data/dev \\\n",
        "    --destdir /content/data \\\n",
        "    --thresholdsrc 5 \\\n",
        "    --thresholdtgt 5 \\\n",
        "    --workers 20"
      ],
      "metadata": {
        "id": "-HQRud8S2xkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cdf94f-5508-4bd5-ffa1-fb8b2e43fa97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 04:01:51 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-05-17 04:01:51 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/content/data', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='ja', srcdict=None, suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=5, thresholdtgt=5, tokenizer=None, tpu=False, trainpref='/content/data/train', use_plasma_view=False, user_dir=None, validpref='/content/data/dev', wandb_project=None, workers=20)\n",
            "2022-05-17 04:03:04 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 53928 types\n",
            "2022-05-17 04:04:22 | INFO | fairseq_cli.preprocess | [ja] /content/data/train.ja: 440288 sents, 11550262 tokens, 1.24% replaced (by <unk>)\n",
            "2022-05-17 04:04:22 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 53928 types\n",
            "2022-05-17 04:04:23 | INFO | fairseq_cli.preprocess | [ja] /content/data/dev.ja: 1166 sents, 26468 tokens, 1.24% replaced (by <unk>)\n",
            "2022-05-17 04:04:23 | INFO | fairseq_cli.preprocess | [en] Dictionary: 55472 types\n",
            "2022-05-17 04:05:20 | INFO | fairseq_cli.preprocess | [en] /content/data/train.en: 440288 sents, 12321279 tokens, 1.56% replaced (by <unk>)\n",
            "2022-05-17 04:05:20 | INFO | fairseq_cli.preprocess | [en] Dictionary: 55472 types\n",
            "2022-05-17 04:05:21 | INFO | fairseq_cli.preprocess | [en] /content/data/dev.en: 1166 sents, 26101 tokens, 2.83% replaced (by <unk>)\n",
            "2022-05-17 04:05:21 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! fairseq-train /content/data --arch transformer \\\n",
        "    --criterion label_smoothed_cross_entropy \\\n",
        "    --label-smoothing 0.1 \\\n",
        "    --lr 1e-5 \\\n",
        "    --lr-scheduler inverse_sqrt \\\n",
        "    --warmup-updates 3000 \\\n",
        "    --optimizer adam \\\n",
        "    --max-tokens 4000 \\\n",
        "    --max-epoch 3 \\\n",
        "    --dropout 0.1 \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --weight-decay 0.0001 \\\n",
        "    --patience 5 \\\n",
        "    --no-epoch-checkpoints > 91.log \\"
      ],
      "metadata": {
        "id": "jAkWNZeX-Wyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7cc9d39-04d5-4cc9-eb09-794dcf821d82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 001:   0% 0/3618 [00:00<?, ?it/s]/content/fairseq/fairseq/utils.py:375: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "epoch 001: 100% 3617/3618 [18:47<00:00,  3.28it/s, loss=9.621, nll_loss=8.709, ppl=418.62, wps=10872.2, ups=3.24, wpb=3352.1, bsz=121.3, num_updates=3600, lr=9.12871e-06, gnorm=2.142, train_wall=31, gb_free=11, wall=1122]\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 1/14 [00:00<00:02,  6.21it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 3/14 [00:00<00:01,  9.28it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  36% 5/14 [00:00<00:00,  9.91it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 7/14 [00:00<00:00, 10.28it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  64% 9/14 [00:00<00:00, 10.54it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 11/14 [00:01<00:00, 10.65it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 13/14 [00:01<00:00, 12.20it/s]\u001b[A\n",
            "epoch 002: 100% 3617/3618 [18:48<00:00,  3.22it/s, loss=8.941, nll_loss=7.917, ppl=241.61, wps=10949.8, ups=3.19, wpb=3428.9, bsz=113.6, num_updates=7200, lr=6.45497e-06, gnorm=2.017, train_wall=31, gb_free=10.7, wall=2259]\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   7% 1/14 [00:00<00:02,  5.90it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  21% 3/14 [00:00<00:01,  9.30it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  36% 5/14 [00:00<00:00,  9.92it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  50% 7/14 [00:00<00:00, 10.27it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  64% 9/14 [00:00<00:00, 10.63it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  79% 11/14 [00:01<00:00, 10.77it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  93% 13/14 [00:01<00:00, 12.40it/s]\u001b[A\n",
            "epoch 003: 100% 3617/3618 [18:48<00:00,  3.28it/s, loss=8.596, nll_loss=7.521, ppl=183.72, wps=10758.9, ups=3.23, wpb=3334.5, bsz=110.8, num_updates=10800, lr=5.27046e-06, gnorm=2.139, train_wall=31, gb_free=10.9, wall=3396]\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:   7% 1/14 [00:00<00:02,  5.64it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  21% 3/14 [00:00<00:01,  8.80it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  36% 5/14 [00:00<00:00,  9.60it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  50% 7/14 [00:00<00:00, 10.04it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  64% 9/14 [00:00<00:00, 10.45it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  79% 11/14 [00:01<00:00, 10.61it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  93% 13/14 [00:01<00:00, 12.24it/s]\u001b[A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/checkpoints/checkpoint_best.pt \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best.pt\""
      ],
      "metadata": {
        "id": "devUlaq_l7kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4918aa0f-dca4-46c5-f981-793cb7a46880"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive/Colab Notebooks/checkpoint_best.pt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "92.91で学習したニューラル機械翻訳モデルを用い，与えられた（任意の）日本語の文を英語に翻訳するプログラムを実装せよ．"
      ],
      "metadata": {
        "id": "rmiL1oodi3kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-interactive --path /content/checkpoints/checkpoint_best.pt /content/data < /content/data/test.ja | grep '^H' | cut -f3 > translate_92.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZzysUOZ-rmc",
        "outputId": "a92cb837-1fff-4e49-bff1-89b38db9fe2c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 05:02:48 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-05-17 05:02:50 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/checkpoints/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1, 'input': '-'}, 'model': None, 'task': {'_name': 'translation', 'data': '/content/data', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-05-17 05:02:50 | INFO | fairseq.tasks.translation | [ja] dictionary: 53928 types\n",
            "2022-05-17 05:02:50 | INFO | fairseq.tasks.translation | [en] dictionary: 55472 types\n",
            "2022-05-17 05:02:50 | INFO | fairseq_cli.interactive | loading model(s) from /content/checkpoints/checkpoint_best.pt\n",
            "2022-05-17 05:02:56 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-05-17 05:02:56 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "2022-05-17 05:07:16 | INFO | fairseq_cli.interactive | Total time: 266.258 seconds; translation time: 254.946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "93.91で学習したニューラル機械翻訳モデルの品質を調べるため，評価データにおけるBLEUスコアを測定せよ．"
      ],
      "metadata": {
        "id": "-_ZooRhDkFZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-score --sys translate_92.out --ref /content/data/test.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiKnof8wDtkS",
        "outputId": "5a50f71c-7bd1-4d70-920b-f27db6e75163"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-17 05:07:18 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "Namespace(ignore_case=False, order=4, ref='/content/data/test.en', sacrebleu=False, sentence_bleu=False, sys='translate_92.out')\n",
            "BLEU4 = 2.26, 21.6/3.9/1.0/0.3 (BP=1.000, ratio=1.007, syslen=27838, reflen=27636)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "94.91で学習したニューラル機械翻訳モデルで翻訳文をデコードする際に，ビーム探索を導入せよ．ビーム幅を1から100くらいまで適当に変化させながら，開発セット上のBLEUスコアの変化をプロットせよ"
      ],
      "metadata": {
        "id": "Ns527sP-rlJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best.pt\" < /content/data/test.ja --beam 1 | grep '^H' | cut -f3 > translate_92_1.out\n",
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best.pt\" < /content/data/test.ja --beam 25 | grep '^H' | cut -f3 > translate_92_25.out\n",
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best.pt\" < /content/data/test.ja --beam 50 | grep '^H' | cut -f3 > translate_92_50.out\n",
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best.pt\" < /content/data/test.ja --beam 75 | grep '^H' | cut -f3 > translate_92_75.out\n",
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best.pt\" < /content/data/test.ja --beam 100 | grep '^H' | cut -f3 > translate_92_100.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbVXcmNX82gg",
        "outputId": "f6e321c2-cb0d-494d-a273-1ebd39add710"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: /content/data/test.ja: No such file or directory\n",
            "/bin/bash: /content/data/test.ja: No such file or directory\n",
            "/bin/bash: /content/data/test.ja: No such file or directory\n",
            "/bin/bash: /content/data/test.ja: No such file or directory\n",
            "/bin/bash: /content/data/test.ja: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-score --sys translate_92_1.out --ref /content/data/test.en > /content/BLEU_score_1\n",
        "!fairseq-score --sys translate_92_25.out --ref /content/data/test.en > /content/BLEU_score_25\n",
        "!fairseq-score --sys translate_92_50.out --ref /content/data/test.en > /content/BLEU_score_50\n",
        "!fairseq-score --sys translate_92_75.out --ref /content/data/test.en > /content/BLEU_score_75\n",
        "!fairseq-score --sys translate_92_100.out --ref /content/data/test.en > /content/BLEU_score_100"
      ],
      "metadata": {
        "id": "SQ7R0w_V-ECk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f24e01-de87-41e2-de40-111f2aa2383e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: fairseq-score: command not found\n",
            "/bin/bash: fairseq-score: command not found\n",
            "/bin/bash: fairseq-score: command not found\n",
            "/bin/bash: fairseq-score: command not found\n",
            "/bin/bash: fairseq-score: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "def cal_score(file):\n",
        "    with open(file) as f:\n",
        "        line = f.readlines()[1]\n",
        "        line = re.search(r\"(?<=BLEU4 = )\\d*\\.\\d*(?=,)\", line)\n",
        "        return float(line.group())\n",
        "\n",
        "x = [1, 25, 50, 75, 100]\n",
        "y = [cal_score(\"/content/BLEU_score_{}\".format(n)) for n in x]\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"beam_size\")\n",
        "plt.ylabel(\"BLEU\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G65OAgfN-hrI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "b919fc86-1036-45f4-c4c2-cd1a6e8d57f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ea45deb1993e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcal_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/BLEU_score_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beam_size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ea45deb1993e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcal_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/BLEU_score_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beam_size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ea45deb1993e>\u001b[0m in \u001b[0;36mcal_score\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcal_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"(?<=BLEU4 = )\\d*\\.\\d*(?=,)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "95.トークンの単位を単語や形態素からサブワードに変更し，91-94の実験を再度実施せよ．"
      ],
      "metadata": {
        "id": "NTub_4Vnc4Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "SH526FvUaiXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import re\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\"--input=kftt-data-1.0/data/orig/kyoto-train.ja --model_prefix=kyoto_ja --vocab_size=16000 --character_coverage=1.0\")\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(\"kyoto_ja.model\")\n",
        "\n",
        "for src, dst in [\n",
        "    (\"kftt-data-1.0/data/orig/kyoto-train.ja\", \"/content/data/train.ja\"),\n",
        "    (\"kftt-data-1.0/data/orig/kyoto-dev.ja\", \"/content/data/dev.ja\"),\n",
        "    (\"kftt-data-1.0/data/orig/kyoto-test.ja\", \"/content/data/test.ja\"),\n",
        "]:\n",
        "    with open(src) as f, open(dst, 'w') as g:\n",
        "        for x in f:\n",
        "            x = x.strip()\n",
        "            x = re.sub(r'\\s+', ' ', x)\n",
        "            x = sp.encode_as_pieces(x)\n",
        "            x = \" \".join(x)\n",
        "            print(x, file=g)"
      ],
      "metadata": {
        "id": "4SmCSSLwc--8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install subword-nmt"
      ],
      "metadata": {
        "id": "yXA7CjC4g2_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!subword-nmt learn-bpe -s 16000 < kftt-data-1.0/data/orig/kyoto-train.en > kyoto_en.codes\n",
        "!subword-nmt apply-bpe -c kyoto_en.codes < kftt-data-1.0/data/orig/kyoto-train.en > /content/data/train.en\n",
        "!subword-nmt apply-bpe -c kyoto_en.codes < kftt-data-1.0/data/orig/kyoto-dev.en > /content/data/dev.en\n",
        "!subword-nmt apply-bpe -c kyoto_en.codes < kftt-data-1.0/data/orig/kyoto-test.en > /content/data/test.en"
      ],
      "metadata": {
        "id": "W6NqtDOZapth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd /content/fairseq/\n",
        "!python -m pip install --editable .\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "K3gujnp2aKSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\""
      ],
      "metadata": {
        "id": "9zMsRkLKaZj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess -s ja -t en \\\n",
        "    --trainpref /content/data/train \\\n",
        "    --validpref /content/data/dev \\\n",
        "    --destdir /content/data \\\n",
        "    --thresholdsrc 5 \\\n",
        "    --thresholdtgt 5 \\\n",
        "    --workers 20"
      ],
      "metadata": {
        "id": "mbbVfHFAbDRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! fairseq-train /content/data --arch transformer \\\n",
        "    --criterion label_smoothed_cross_entropy \\\n",
        "    --label-smoothing 0.1 \\\n",
        "    --lr 1e-5 \\\n",
        "    --lr-scheduler inverse_sqrt \\\n",
        "    --warmup-updates 3000 \\\n",
        "    --optimizer adam \\\n",
        "    --max-tokens 4000 \\\n",
        "    --max-epoch 3 \\\n",
        "    --dropout 0.1 \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --weight-decay 0.0001 \\\n",
        "    --patience 5 \\\n",
        "    --no-epoch-checkpoints > 95.log \\"
      ],
      "metadata": {
        "id": "Iw6PmwuYbH7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8jf4qmYVAb2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/checkpoints/checkpoint_best.pt \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_2.pt\""
      ],
      "metadata": {
        "id": "i-zvgmfmbK39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-interactive --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_2.pt\" /content/data < /content/data/test.ja | grep '^H' | cut -f3 > translate_95.out"
      ],
      "metadata": {
        "id": "avvYrYaSbREk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-score --sys translate_95.out --ref /content/data/test.en"
      ],
      "metadata": {
        "id": "zOAg9WCObhY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_2.pt\" < /content/data/test.ja --beam 1 | grep '^H' | cut -f3 > translate_95_1.out\n",
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_2.pt\" < /content/data/test.ja --beam 25 | grep '^H' | cut -f3 > translate_95_25.out\n",
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_2.pt\" < /content/data/test.ja --beam 50 | grep '^H' | cut -f3 > translate_95_50.out\n",
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_2.pt\" < /content/data/test.ja --beam 75 | grep '^H' | cut -f3 > translate_95_75.out\n",
        "!fairseq-interactive /content/data --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_2.pt\" < /content/data/test.ja --beam 100 | grep '^H' | cut -f3 > translate_95_100.out"
      ],
      "metadata": {
        "id": "LYx-2X2Pbls-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-score --sys translate_95_1.out --ref /content/data/test.en > /content/BLEU_score_1\n",
        "!fairseq-score --sys translate_95_25.out --ref /content/data/test.en > /content/BLEU_score_25\n",
        "!fairseq-score --sys translate_95_50.out --ref /content/data/test.en > /content/BLEU_score_50\n",
        "!fairseq-score --sys translate_95_75.out --ref /content/data/test.en > /content/BLEU_score_75\n",
        "!fairseq-score --sys translate_95_100.out --ref /content/data/test.en > /content/BLEU_score_100"
      ],
      "metadata": {
        "id": "MR-HBx42vb5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "def cal_score(file):\n",
        "    with open(file) as f:\n",
        "        line = f.readlines()[1]\n",
        "        line = re.search(r\"(?<=BLEU4 = )\\d*\\.\\d*(?=,)\", line)\n",
        "        return float(line.group())\n",
        "\n",
        "x = [1, 25, 50, 75, 100]\n",
        "y = [cal_score(\"/content/BLEU_score_{}\".format(n)) for n in x]\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"beam_size\")\n",
        "plt.ylabel(\"BLEU\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ujr-40jfviT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "96.Tensorboardなどのツールを用い，ニューラル機械翻訳モデルが学習されていく過程を可視化せよ．可視化する項目としては，学習データにおける損失関数の値とBLEUスコア，開発データにおける損失関数の値とBLEUスコアなどを採用せよ"
      ],
      "metadata": {
        "id": "CbMtCyCWdFFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "pZT4o8pGM6KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-train /content/data --arch transformer\\\n",
        "    --tensorboard-logdir log96 \\\n",
        "    --save-dir save96 \\\n",
        "    --max-epoch 3 \\\n",
        "    --optimizer adam --clip-norm 1.0 \\\n",
        "    --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 3000 \\\n",
        "    --dropout 0.1 --weight-decay 0.0001 \\\n",
        "    --update-freq 1 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --max-tokens 4000 > 96.log"
      ],
      "metadata": {
        "id": "2W3Zaetos8vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir log96"
      ],
      "metadata": {
        "id": "8h21R0XaC9lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "97.ニューラルネットワークのモデルや，そのハイパーパラメータを変更しつつ，開発データにおけるBLEUスコアが最大となるモデルとハイパーパラメータを求めよ．"
      ],
      "metadata": {
        "id": "ua4lwvNvdRAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-train /content/data --arch transformer \\\n",
        "    --save-dir save97 \\\n",
        "    --max-epoch 3 \\\n",
        "    --optimizer adam --clip-norm 1.0 \\\n",
        "    --lr 3e-3 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "    --dropout 0.3 --weight-decay 0.0001 \\\n",
        "    --update-freq 1 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --max-tokens 6000 > 97.log"
      ],
      "metadata": {
        "id": "oQU2WPlts0M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/save97/checkpoint_best.pt \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_3.pt\""
      ],
      "metadata": {
        "id": "FBeAAM0uuVsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-interactive --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_3.pt\" /content/data < /content/data/test.ja --beam 10 | grep '^H' | cut -f3 > translate_97.out"
      ],
      "metadata": {
        "id": "TNj77NpXucAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-score --sys translate_97.out --ref /content/data/test.en"
      ],
      "metadata": {
        "id": "5Eve5YpBusd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "98.Japanese-English Subtitle Corpus (JESC)やJParaCrawlなどの翻訳データを活用し，KFTTのテストデータの性能向上を試みよ．"
      ],
      "metadata": {
        "id": "dk1YbmyMda6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess -s ja -t en \\\n",
        "    --trainpref \"/content/drive/MyDrive/Colab Notebooks/train.jesc\" \\\n",
        "    --validpref /content/data/dev \\\n",
        "    --destdir /content/data \\\n",
        "    --thresholdsrc 5 \\\n",
        "    --thresholdtgt 5 \\\n",
        "    --workers 20"
      ],
      "metadata": {
        "id": "nCGJsAZjCq7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! fairseq-train /content/data --arch transformer \\\n",
        "    --criterion label_smoothed_cross_entropy \\\n",
        "    --label-smoothing 0.1 \\\n",
        "    --lr 1e-5 \\\n",
        "    --lr-scheduler inverse_sqrt \\\n",
        "    --warmup-updates 3000 \\\n",
        "    --optimizer adam \\\n",
        "    --max-tokens 4000 \\\n",
        "    --max-epoch 1 \\\n",
        "    --dropout 0.1 \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --weight-decay 0.0001 \\\n",
        "    --patience 5 \\\n",
        "    --no-epoch-checkpoints > 98_1.log \\"
      ],
      "metadata": {
        "id": "HM-e0UPxL7w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/checkpoints/checkpoint_best.pt \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_4.pt\""
      ],
      "metadata": {
        "id": "-584CO6xFn8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-interactive --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_4.pt\" /content/data < /content/data/test.ja | grep '^H' | cut -f3 > translate_98_1.out"
      ],
      "metadata": {
        "id": "2-taD_LbC15k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-preprocess -s ja -t en \\\n",
        "    --trainpref /content/data/train \\\n",
        "    --validpref /content/data/dev \\\n",
        "    --destdir /content/data \\\n",
        "    --tgtdict /content/data/dict.en.txt \\\n",
        "    --srcdict /content/data/dict.ja.txt \\\n",
        "    --thresholdsrc 5 \\\n",
        "    --thresholdtgt 5 \\\n",
        "    --workers 20"
      ],
      "metadata": {
        "id": "phxjfY2xIHhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! fairseq-train /content/data --arch transformer \\\n",
        "    --criterion label_smoothed_cross_entropy \\\n",
        "    --label-smoothing 0.1 \\\n",
        "    --lr 1e-5 \\\n",
        "    --lr-scheduler inverse_sqrt \\\n",
        "    --warmup-updates 3000 \\\n",
        "    --optimizer adam \\\n",
        "    --max-tokens 4000 \\\n",
        "    --max-epoch 2 \\\n",
        "    --dropout 0.1 \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --weight-decay 0.0001 \\\n",
        "    --patience 5 \\\n",
        "    --no-epoch-checkpoints > 98_2.log \\"
      ],
      "metadata": {
        "id": "SlraNlznbJMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/checkpoints/checkpoint_best.pt \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_5.pt\""
      ],
      "metadata": {
        "id": "ADu7VBjEIuTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-interactive --path \"/content/drive/MyDrive/Colab Notebooks/checkpoint_best_5.pt\" /content/data < /content/data/test.ja | grep '^H' | cut -f3 > translate_98_2.out"
      ],
      "metadata": {
        "id": "S57J9cSRIw1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!fairseq-score --sys translate_98_2.out --ref /content/data/test.en"
      ],
      "metadata": {
        "id": "WIm_nnqmI5eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "99.ユーザが翻訳したい文を入力すると，その翻訳結果がウェブブラウザ上で表示されるデモシステムを構築せよ．"
      ],
      "metadata": {
        "id": "Nt4Rt4SmdkSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok"
      ],
      "metadata": {
        "id": "Iz_eqEpWrPSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, render_template, request"
      ],
      "metadata": {
        "id": "zGCP3PFOrNEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairseq"
      ],
      "metadata": {
        "id": "SZap1buZOe1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fairseq.models.transformer import TransformerModel"
      ],
      "metadata": {
        "id": "lAk_fhUAXStN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel.from_pretrained(\n",
        "    '/content/checkpoints/',\n",
        "    checkpoint_file=\"checkpoint_best.pt\",\n",
        "    data_name_or_path=\"/content/data\",\n",
        ")"
      ],
      "metadata": {
        "id": "5HmPnbhLXL-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__,template_folder=\"(前略)/templates\")\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def get():\n",
        "    return render_template(\"index.html\", \\\n",
        "        title = \"翻訳\", \\\n",
        "        message = \"入力してください\")\n",
        "\n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def post():\n",
        "    text = request.form[\"name\"]\n",
        "    return render_template(\"index.html\", \\\n",
        "        title = \"翻訳\", \\\n",
        "        output = model.translate(text, beam=1)\n",
        "        message = text+\"　　　　　　　→　\"+output)\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "id": "JnhL1wfVsINF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}